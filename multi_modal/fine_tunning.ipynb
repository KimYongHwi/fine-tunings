{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data.data_load import get_neckline_df, get_device, download_images\n",
    "from data_set import get_dataset, print_dataset_names\n",
    "from torch.utils.data import DataLoader\n",
    "from fashion_clip.pretrained_model import get_model, train_step\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cb2806dd9d27f30",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_size = 20\n",
    "\n",
    "train_df, test_df = get_neckline_df('neck_line_concated.csv', 'neck_line_test_item_no_list.txt', data_size=data_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bb14800750a42190",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc8af7f6a8f66fa4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9d865da80041c17",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_urls = [url for url in train_df['detail_image_url_1'].tolist()]\n",
    "train_labels = train_df['neck_line_label'].tolist()\n",
    "train_item_no_list = train_df['item_no'].tolist()\n",
    "train_sentences = train_df['neck_line_label_desc'].tolist()\n",
    "\n",
    "test_urls = [url for url in test_df['detail_image_url_1'].tolist()]\n",
    "test_labels = test_df['neck_line_label'].tolist()\n",
    "test_item_no_list = test_df['item_no'].tolist()\n",
    "test_sentences = test_df['neck_line_label_desc'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ff985184fa41f906",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "download_images(train_urls)\n",
    "download_images(test_urls)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f6744a91989e458f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "print_dataset_names()\n",
    "dataset = get_dataset(train_item_no_list, train_urls, train_sentences, train_labels, 'CustomDatasetWithOutProcessor')\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f607e38fcd3f572d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "clip_model = get_model(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fcc8a002e897081",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr=1e-6\n",
    "\n",
    "optimizer = torch.optim.Adam(clip_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-6, weight_decay=0.2)\n",
    "img_criterion = torch.nn.CrossEntropyLoss()\n",
    "txt_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2, eta_min=0)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "32ccba1b0e3ae5f3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Loss: 3.1842846870422363, Img Loss: 3.124016284942627, Txt Loss: 3.2445532083511353, LR: [9.179036806841351e-07]\n",
      "Epoch [20/1000], Loss: 3.1503570079803467, Img Loss: 3.0817757844924927, Txt Loss: 3.2189382314682007, LR: [8.698155474893048e-07]\n",
      "Epoch [30/1000], Loss: 3.1723897457122803, Img Loss: 3.102574586868286, Txt Loss: 3.2422049045562744, LR: [8.126213281678525e-07]\n",
      "Epoch [40/1000], Loss: 3.123449683189392, Img Loss: 3.066511034965515, Txt Loss: 3.180388331413269, LR: [7.477293342162037e-07]\n",
      "Epoch [50/1000], Loss: 3.1395249366760254, Img Loss: 3.082792282104492, Txt Loss: 3.1962573528289795, LR: [6.767374218896286e-07]\n",
      "Epoch [60/1000], Loss: 3.147813081741333, Img Loss: 3.081658959388733, Txt Loss: 3.2139673233032227, LR: [6.013936476782562e-07]\n",
      "Epoch [70/1000], Loss: 3.1357086896896362, Img Loss: 3.0837225914001465, Txt Loss: 3.1876946687698364, LR: [5.235532253548213e-07]\n",
      "Epoch [80/1000], Loss: 3.072700023651123, Img Loss: 3.028701901435852, Txt Loss: 3.116698145866394, LR: [4.4513284445447734e-07]\n",
      "Epoch [90/1000], Loss: 3.155734658241272, Img Loss: 3.1059850454330444, Txt Loss: 3.2054842710494995, LR: [3.6806347501731355e-07]\n",
      "Epoch [100/1000], Loss: 3.1198313236236572, Img Loss: 3.072328567504883, Txt Loss: 3.1673340797424316, LR: [2.942428206974456e-07]\n",
      "Epoch [110/1000], Loss: 3.1018149852752686, Img Loss: 3.0482782125473022, Txt Loss: 3.1553516387939453, LR: [2.2548859100093403e-07]\n",
      "Epoch [120/1000], Loss: 3.1320117712020874, Img Loss: 3.0831011533737183, Txt Loss: 3.180922269821167, LR: [1.6349374324511322e-07]\n",
      "Epoch [130/1000], Loss: 3.1285951137542725, Img Loss: 3.0742766857147217, Txt Loss: 3.1829134225845337, LR: [1.097847963308352e-07]\n",
      "Epoch [140/1000], Loss: 3.0750008821487427, Img Loss: 3.0334086418151855, Txt Loss: 3.1165932416915894, LR: [6.568424278090434e-08]\n",
      "Epoch [150/1000], Loss: 3.1410621404647827, Img Loss: 3.087225914001465, Txt Loss: 3.194898247718811, LR: [3.227798458506631e-08]\n",
      "Epoch [160/1000], Loss: 3.1338133811950684, Img Loss: 3.0829436779022217, Txt Loss: 3.184683084487915, LR: [1.0388594689117069e-08]\n",
      "Epoch [170/1000], Loss: 3.1025002002716064, Img Loss: 3.0540395975112915, Txt Loss: 3.150960683822632, LR: [5.550625190150482e-10]\n",
      "Epoch [180/1000], Loss: 3.078883171081543, Img Loss: 3.029602527618408, Txt Loss: 3.128163695335388, LR: [9.99244548725269e-07]\n",
      "Epoch [190/1000], Loss: 3.114743947982788, Img Loss: 3.0651129484176636, Txt Loss: 3.1643749475479126, LR: [9.955498736829874e-07]\n",
      "Epoch [200/1000], Loss: 3.080995798110962, Img Loss: 3.0343236923217773, Txt Loss: 3.1276676654815674, LR: [9.887999688823954e-07]\n",
      "Epoch [210/1000], Loss: 3.0725326538085938, Img Loss: 3.024642586708069, Txt Loss: 3.1204227209091187, LR: [9.790364497311595e-07]\n",
      "Epoch [220/1000], Loss: 3.0868245363235474, Img Loss: 3.043988585472107, Txt Loss: 3.1296603679656982, LR: [9.66319511571547e-07]\n",
      "Epoch [230/1000], Loss: 3.054490566253662, Img Loss: 3.014163613319397, Txt Loss: 3.0948177576065063, LR: [9.507275585561227e-07]\n",
      "Epoch [240/1000], Loss: 3.057352066040039, Img Loss: 3.0115987062454224, Txt Loss: 3.1031055450439453, LR: [9.323567202600775e-07]\n",
      "Epoch [250/1000], Loss: 3.062315821647644, Img Loss: 3.023021697998047, Txt Loss: 3.1016100645065308, LR: [9.113202590104299e-07]\n",
      "Epoch [260/1000], Loss: 3.0887889862060547, Img Loss: 3.044805407524109, Txt Loss: 3.1327725648880005, LR: [8.877478715861173e-07]\n",
      "Epoch [270/1000], Loss: 3.1170315742492676, Img Loss: 3.0743290185928345, Txt Loss: 3.1597342491149902, LR: [8.617848895942246e-07]\n",
      "Epoch [280/1000], Loss: 3.1228405237197876, Img Loss: 3.0744025707244873, Txt Loss: 3.1712783575057983, LR: [8.335913834522998e-07]\n",
      "Epoch [290/1000], Loss: 3.101535677909851, Img Loss: 3.052761197090149, Txt Loss: 3.1503101587295532, LR: [8.033411755009997e-07]\n",
      "Epoch [300/1000], Loss: 3.072462558746338, Img Loss: 3.0387685298919678, Txt Loss: 3.106156826019287, LR: [7.712207683315594e-07]\n",
      "Epoch [310/1000], Loss: 3.0613012313842773, Img Loss: 3.017439365386963, Txt Loss: 3.105163097381592, LR: [7.374281949352972e-07]\n",
      "Epoch [320/1000], Loss: 3.054972767829895, Img Loss: 3.0165082216262817, Txt Loss: 3.0934373140335083, LR: [7.021717977643724e-07]\n",
      "Epoch [330/1000], Loss: 3.097737431526184, Img Loss: 3.044917106628418, Txt Loss: 3.15055775642395, LR: [6.656689442312855e-07]\n",
      "Epoch [340/1000], Loss: 3.0713781118392944, Img Loss: 3.034760355949402, Txt Loss: 3.107995867729187, LR: [6.281446865664982e-07]\n",
      "Epoch [350/1000], Loss: 3.0514931678771973, Img Loss: 3.0078344345092773, Txt Loss: 3.095151662826538, LR: [5.898303742965962e-07]\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    clip_model.train()\n",
    "    running_loss = 0.0\n",
    "    running_img_loss = 0.0\n",
    "    running_txt_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    # for batch_data in tqdm(train_dataloader):\n",
    "    for batch_data in train_dataloader:\n",
    "        outputs = train_step(clip_model, device, batch_data, return_loss=True)\n",
    "\n",
    "        logits_per_image = outputs.logits_per_image\n",
    "        logits_per_text = outputs.logits_per_text\n",
    "\n",
    "        target = torch.arange(len(logits_per_image), device=device)\n",
    "        \n",
    "        img_loss = torch.nn.functional.cross_entropy(logits_per_image, target)\n",
    "        # txt_loss = txt_criterion(logits_per_text, target)\n",
    "        txt_loss = torch.nn.functional.cross_entropy(logits_per_text, target)\n",
    "        # txt_loss = txt_criterion(logits_per_text, target)\n",
    "        \n",
    "        loss = (img_loss + txt_loss) / 2\n",
    "\n",
    "        # loss = (txt_criterion(logits_per_text, batch_labels) + img_criterion(logits_per_image, batch_labels)) / 2\n",
    "\n",
    "        # loss = txt_criterion(logits_per_text, batch_labels)\n",
    "\n",
    "        # loss = img_criterion(logits_per_text, batch_labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_img_loss += img_loss.item()\n",
    "        running_txt_loss += txt_loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader)}, Img Loss: {running_img_loss / len(train_dataloader)}, Txt Loss: {running_txt_loss / len(train_dataloader)}, LR: {scheduler.get_last_lr()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-18T14:48:54.202122Z"
    }
   },
   "id": "1d4a133bb5e0f419",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a057f175e0b1c5ea",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
