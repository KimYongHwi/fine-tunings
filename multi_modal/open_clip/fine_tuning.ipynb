{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from data.data_load import get_neckline_df, get_device, download_images\n",
    "from multi_modal.data_set import get_dataset, print_dataset_names\n",
    "from torch.utils.data import DataLoader\n",
    "from multi_modal.open_clip.pretrained_model import get_model, train_step"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = get_device()\n",
    "device"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7117911633d9ebe3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "data_size = 1\n",
    "\n",
    "train_df, test_df = get_neckline_df('neck_line_concated.csv', 'neck_line_test_item_no_list.txt', data_size=data_size)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5b3e8535a7727ffc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "df95d8410d1c493",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "test_df"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c0ae420d64bd9685",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_urls = [url for url in train_df['detail_image_url_1'].tolist()]\n",
    "train_labels = train_df['neck_line_label'].tolist()\n",
    "train_item_no_list = train_df['item_no'].tolist()\n",
    "train_sentences = train_df['neck_line_label_desc'].tolist()\n",
    "\n",
    "test_urls = [url for url in test_df['detail_image_url_1'].tolist()]\n",
    "test_labels = test_df['neck_line_label'].tolist()\n",
    "test_item_no_list = test_df['item_no'].tolist()\n",
    "test_sentences = test_df['neck_line_label_desc'].tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7f27e38948a4ac9e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "download_images(train_urls)\n",
    "download_images(test_urls)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "51eeaa60cab8818a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print_dataset_names()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "70ea68df5f29d92b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "dataset = get_dataset(train_item_no_list, train_urls, train_sentences, train_labels, 'CustomDatasetWithPreprocessor')\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c9cc92df8e1297fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "open_clip_model = get_model(device)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "703b61683def7392",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "lr=1e-6\n",
    "EPOCH=5000\n",
    "\n",
    "# optimizer = torch.optim.Adam(open_clip_model.parameters(), lr=lr, betas=(0.9, 0.98), eps=1e-6, weight_decay=0.2)\n",
    "optimizer = torch.optim.Adam(open_clip_model.parameters(), lr=1e-5)\n",
    "\n",
    "img_criterion = torch.nn.CrossEntropyLoss()\n",
    "txt_criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=100, T_mult=2, eta_min=0)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_dataloader)*EPOCH)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "89c561524097b899",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def convert_models_to_fp32(model): \n",
    "    for p in model.parameters(): \n",
    "        p.data = p.data.float()\n",
    "        p.grad.data = p.grad.data.float() "
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f115cda4e1227496",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    open_clip_model.train()\n",
    "    running_loss = 0.0\n",
    "    running_img_loss = 0.0\n",
    "    running_txt_loss = 0.0\n",
    "    predictions = []\n",
    "    targets = []\n",
    "\n",
    "    # for batch_data in tqdm(train_dataloader):\n",
    "    for batch_data in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = train_step(open_clip_model, device, batch_data)\n",
    "\n",
    "        logits_per_image, logits_per_text, _ = outputs\n",
    "        \n",
    "        print(logits_per_image)\n",
    "\n",
    "        target = torch.arange(len(logits_per_image), device=device)\n",
    "        \n",
    "        img_loss = img_criterion(logits_per_text, target)\n",
    "        txt_loss = txt_criterion(logits_per_text, target)\n",
    "        \n",
    "        loss = (img_loss + txt_loss) / 2\n",
    "\n",
    "        loss.backward()\n",
    "        # convert_models_to_fp32(open_clip_model)\n",
    "        optimizer.step()\n",
    "        # clip.model.convert_weights(open_clip_model)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_img_loss += img_loss.item()\n",
    "        running_txt_loss += txt_loss.item()\n",
    "        \n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {running_loss / len(train_dataloader)}, Img Loss: {running_img_loss / len(train_dataloader)}, Txt Loss: {running_txt_loss / len(train_dataloader)}, LR: {scheduler.get_last_lr()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9589ac727ed7a22d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f51f282931c603a4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
